{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNutoDU3PqFplH9ErBG/pv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunnyZhao2004/Data_Project/blob/main/president_party.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### This chunk is for setup ########################\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the path to the shared folder on your Google Drive\n",
        "data_folder = '/content/drive/My Drive/0812Fullmerged/'\n",
        "\n",
        "# Get all Parquet files in the shared folder\n",
        "all_files = glob.glob(data_folder + \"*.parquet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnbuw-On_jua",
        "outputId": "6de23f81-eef0-49f3-98f0-c7be85e8a95e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##################### This is for president party merging ################\n",
        "# Step 1: Load the president term data from Excel\n",
        "president_terms_file = '/content/drive/My Drive/Data/president_terms.xlsx'\n",
        "president_terms = pd.read_excel(president_terms_file)\n",
        "\n",
        "# Step 2: Loop through each Parquet file, process it, and save the results\n",
        "for file_path in all_files:\n",
        "    # Load the Parquet file\n",
        "    df = pd.read_parquet(file_path)\n",
        "\n",
        "    # Ensure action_date is in datetime format\n",
        "    df['action_date'] = pd.to_datetime(df['action_date'], format='mixed')\n",
        "\n",
        "    # Step 1: Initialize an empty president_party column\n",
        "    df['president_party'] = None\n",
        "\n",
        "    # Step 2: Apply the president terms to the data\n",
        "    for _, row in president_terms.iterrows():\n",
        "        # Create a mask where action_date is between the president's start and end dates\n",
        "        mask = (df['action_date'] >= row['Start_date']) & (df['action_date'] <= row['End_date'])\n",
        "\n",
        "        # Assign the president's party based on the mask\n",
        "        df.loc[mask, 'president_party'] = row['Party']\n",
        "\n",
        "    # Get the file name from the file path (to use in output)\n",
        "    file_name = file_path.split('/')[-1].replace('.parquet', '_processed.parquet')\n",
        "\n",
        "    # Save the processed data with a new name\n",
        "    output_file = f'/content/drive/My Drive/Data/{file_name}'\n",
        "    df.to_parquet(output_file, index=False)\n",
        "\n",
        "    print(f'Processed and saved file: {output_file}')"
      ],
      "metadata": {
        "id": "mFlGCFPXDqcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Step 1: Load the `psc_codes_by_category` file once outside the loop\n",
        "psc_codes = pd.read_csv('/content/drive/My Drive/Data/psc_codes_by_category.csv')\n",
        "\n",
        "# Create a dictionary for fast lookup of 'industry_category'\n",
        "psc_dict = psc_codes.set_index('4-Digit PSC')['Category'].to_dict()\n",
        "\n",
        "# Step 3: Loop through each Parquet file, process it, and save the results\n",
        "for idx, file_path in enumerate(all_files, 1):\n",
        "    # Load the Parquet file\n",
        "    df = pd.read_parquet(file_path)\n",
        "\n",
        "    # Ensure `product_or_service_code` is a string for mapping\n",
        "    df['product_or_service_code'] = df['product_or_service_code'].astype(str)\n",
        "\n",
        "    # Map `product_or_service_code` to `industry_category` using the dictionary\n",
        "    df['industry_category'] = df['product_or_service_code'].map(psc_dict)\n",
        "\n",
        "    # Step 4: Save the processed file with a new name\n",
        "    output_file = f'/content/drive/My Drive/Data/0812_merged_chunk_{idx}_with_industry_category.parquet'\n",
        "    df.to_parquet(output_file, index=False)\n",
        "\n",
        "    print(f'Processed and saved file: {output_file}')\n"
      ],
      "metadata": {
        "id": "VT18fWqH_jrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############ debug: set df to the first file ##############\n",
        "data_folder = '/content/drive/My Drive/0812Fullmerged/0812_merged_chunk_1.parquet'\n",
        "df2 = pd.read_parquet(data_folder)"
      ],
      "metadata": {
        "id": "tkBerS4BEY1P"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df2['product_or_service_code'])"
      ],
      "metadata": {
        "id": "_ff5wEBkITpX",
        "outputId": "146cb0bd-7a6f-4bde-c470-1606c0f9d5d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0          V231\n",
            "1          Z111\n",
            "2          L016\n",
            "3          C211\n",
            "4          R408\n",
            "           ... \n",
            "7709931    5680\n",
            "7709932    6220\n",
            "7709933    5680\n",
            "7709934    5680\n",
            "7709935    5680\n",
            "Name: product_or_service_code, Length: 7709936, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Load the `psc_codes_by_category` file\n",
        "psc_codes = pd.read_csv('/content/drive/My Drive/Data/psc_codes_by_category.csv' )\n",
        "\n",
        "# Create a dictionary for fast lookup of 'industry_category'\n",
        "psc_dict = psc_codes.set_index('4-Digit PSC')['Category'].to_dict()\n",
        "\n",
        "# Ensure `product_or_service_code` is a string for mapping\n",
        "df['product_or_service_code'] = df['product_or_service_code'].astype(str)\n",
        "\n",
        "# Step 4: Map `product_or_service_code` to `industry_category` using the dictionary\n",
        "df['industry_category'] = df['product_or_service_code'].map(psc_dict)\n",
        "\n",
        "# Create a new folder in your Google Drive (e.g., \"ProcessedFiles\")\n",
        "output_file = '/content/drive/My Drive/Data/0812_merged_chunk_1_with_industry_category.parquet'\n",
        "df.to_parquet(output_file, index=False)\n",
        "\n",
        "print(f'Processed and saved file: {output_file}')\n"
      ],
      "metadata": {
        "id": "AeQ86YHD_jjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac859ebd-f1e2-4a2c-b5ab-aa3a1def881e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved file: /content/drive/My Drive/Data/0812_merged_chunk_1_with_industry_category.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('/content/drive/My Drive/Data/0812_merged_chunk_1_with_industry_category.parquet')"
      ],
      "metadata": {
        "id": "PC8kWNLeG9Hr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_nan_values = np.sum(df['industry_category'].isnull())\n",
        "print(num_nan_values)"
      ],
      "metadata": {
        "id": "ms80rXwwG_tK",
        "outputId": "52adcef1-887f-4045-babf-f6fb42e10c7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "615609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xm35Hpn0KUxd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}